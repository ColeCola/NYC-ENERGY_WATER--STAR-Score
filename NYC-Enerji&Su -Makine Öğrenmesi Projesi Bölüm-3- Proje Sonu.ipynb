{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c53f9fc0dbf017ad3961463c1ecb73fcb73c058e"
   },
   "source": [
    "# Makine Öğrenimi Projesi Bölüm - 3\n",
    "Bu projede gerçek veri setiyle uğraşan eksiksiz bir makine öğrenim problemi üzerinde çalışıyoruz. Bina enerji verilerini kullanarak, bir binanın \"Enerji Yıldızı Puanını\" tahmin etmek için bir model oluşturmaya çalışıyoruz, bu işlemi de denetimli bir gerileme(supervised regression), makine öğrenimi görevi tarafından gerçekleştiriyoruz.\n",
    "\n",
    "Bu projenin ilk iki bölümünde, makine öğrenme işlemlerinin ilk 6 adımını uyguladık:\n",
    "\n",
    "1.Veri temizleme ve biçimlendirme\n",
    "2.Keşifsel veri analizi\n",
    "3.Özellik mühendisliği ve seçimi\n",
    "4.Bir performans metriğinde çeşitli makine öğrenim modellerinin karşılaştırılması\n",
    "5.Problem için optimize etmek üzere en iyi modele hiperparametre ayarlaması yapılması\n",
    "6.Test setindeki en iyi modelin değerlendirilmesi\n",
    "7.Model sonuçlarının en iyi şekilde yorumlanması\n",
    "8.Sonuçların grafiğini oluşturun ve iyi bir rapor yazın\n",
    "\n",
    "Bu not defterinde, son iki adıma yoğunlaşacağız ve kurduğumuz modelin kara kutusuna bakmaya çalışacağız. Oluşturduğumuz modelin doğru olduğunu biliyoruz, çünkü Energy Yıldız Puanının gerçek değeri 9.1 noktası içinde öngörebiliyor, ancak bu tahminleri tam olarak nasıl yapıyor? Gradient destek makinesini(Gradient Boosting Machine) anlamaya çalışmanın bazı yollarını inceleyeceğiz ve daha sonra sonuçlar çıkartacağız.\n",
    "\n",
    "Kütüphaneleri eklemekle kodlama çalışmamıza başlıyoruz, Bu çalışmada standart veri bilimi kütüphanelerini kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verileri işlemek için Numpy ve Pandas Kütüphanelerini yüklüyoruz\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bölümler arasında uyarı olmaması için uyarıları kapatıyoruz\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "# Görselleştirme için matplotlib kütüphanesini dahil ediyoruz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "# Yazı boyutlarını varsayılan  olarak 24 punto ayarlıyoruz\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Eksik değerlere etki edecek kütüphaneyi yüklüyoruz\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "\n",
    "# Makine Öğrenmesi modellerini dahil ediyoruz\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "\n",
    "#Tahminleri açıklamak için  LIME kütüphanesini ekliyoruz\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46bff74e116368aef5b74eca5d6691b7bec913f0"
   },
   "source": [
    "## Eğitim ve Test Verilerini alıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Veriçerçevesinden verileri okuyoruz\n",
    "train_features = pd.read_csv('../input/nyctrain-test-data/training_features.csv')\n",
    "test_features = pd.read_csv('../input/nyctrain-test-data/testing_features.csv')\n",
    "train_labels = pd.read_csv('../input/nyctrain-test-data/training_labels.csv')\n",
    "test_labels = pd.read_csv('../input/nyctrain-test-data/testing_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dfb33305a34003c16ad3df00184261073c39fa3"
   },
   "source": [
    "## Modeli Tekrar oluşturuyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4132bd19b778310716798c65428f2efedf136ab2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Median doldurma stratejisi ile bir imputer nesne oluşturuyoruz\n",
    "imputer = Imputer(strategy = 'median')\n",
    "\n",
    "#Eğitim verilerine imputer nesnesini uyguluyoruz\n",
    "imputer.fit(train_features)\n",
    "\n",
    "#Eğtim ve Test verilerini dönüştürüyoruz\n",
    "X = imputer.transform(train_features)\n",
    "X_test = imputer.transform(test_features)\n",
    "\n",
    "#Tek boyutlu vektör için Sklearn de etiketleme yapıyoruz\n",
    "y = np.array(train_labels).reshape((-1,))\n",
    "y_test = np.array(test_labels).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f34923fdbbd8f48029ece93468a02faff30002fe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ortalama mutlak hata'yı(MAE) bulmak için fonksiyonumuz\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "836163b8c36e23d7baa0f626eba7164be60e799c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(loss = 'lad', max_depth = 5, max_features = None,\n",
    "                                 min_samples_leaf = 6, min_samples_split = 6,\n",
    "                                 n_estimators = 800, random_state = 42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7c5674cfb8f043aab043c24d9c0487057524680",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test verileri üzerinde tahminlerimizi yapıyoruz\n",
    "model_pred = model.predict(X_test)\n",
    "\n",
    "print('Test verileri üzerinde son modelimizin performans testi: MAE = %0.4f' % mae(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58a6051307167d449701c0e267319fbd3faa16ef"
   },
   "source": [
    "## Modeli yorumlamak\n",
    "Makine öğrenimi çoğu zaman bir kara kutu olarak eleştirilmektedir: Bir tarafa veri koyduk ve bize diğer tarafta cevapları verdi. Bu cevaplar genellikle son derece doğru olsa da, model bize tahminleri gerçekten nasıl yaptığını anlatmıyor. Bu bir dereceye kadar doğrudur, ancak bir modelin Yerel Olarak Yorumlanabilir Model-agnostik Açıklayıcı (LIME) gibi nasıl düşündüğünü keşfedip deneyebileceğimiz yollar vardır. Bu, tahmin edilebilir bir model olan, tahmin etrafında doğrusal bir regresyon öğrenerek model tahminlerini açıklamayı amaçlamaktadır!\n",
    "\n",
    "Modelimizi yorumlamak için birkaç yolu keşfedeceğiz:\n",
    "\n",
    "-  Özelliklerin önemi\n",
    "- Lokal olarak Yorumlanabilir Model-agnostik Explainer (LIME)\n",
    "- Topluluktaki tek bir karar ağacını incelemek.\n",
    "\n",
    "### Özellik Önemi\n",
    "Karar ağaçlarının bir grubunu yorumlayabilmemizin temel yollarından biri, özellik itirazları olarak bilinen şeydir. Bunlar, hedefin en çok tahmin edilen değişkenleri olarak yorumlanabilir. Öznitelik önemlerinin asıl ayrıntıları oldukça karmaşık olsa da burada konuyla ilgili bir soru var, özellikleri karşılaştırmak ve problemimizle en uygun olanı belirlemek için göreceli değerleri kullanabiliriz.\n",
    "\n",
    "Özelliklerin eğitimli bir topluluktan alınması, scikit-öğrenmede oldukça kolaydır. Bunları analiz etmek ve görselleştirmek için özellikteki bir veri çerçevesine saklayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6001d8ad72793fd1ecad6738ec78b9cb430ea0d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Veri çerçevesi içerisinden önemli özellikleri ayırıyoruz\n",
    "features_results = pd.DataFrame({'features': list(train_features.columns),\n",
    "                                'importance': model.feature_importances_})\n",
    "#içlerinden en önemli 10 tanesine bakalım\n",
    "features_results = features_results.sort_values('importance', ascending = False).reset_index(drop = True)\n",
    "\n",
    "features_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e45d27d0e500f8a670bf27cc589ecfe2c03b2df"
   },
   "source": [
    "Enerji Kullanımı Yoğunluğu (Site EUI (kBtu / ft²)) ve Hava Durumu Normalize Saha Elektrik Yoğunluğu, Hava Normalleştirilmiş Yer Elektrik Yoğunluğu (kWh / ft²), oldukça büyük bir marjla en önemli iki özelliktir. Bundan sonra, göreceli önem, önemli ölçüde düşer ve bu da neredeyse aynı performansa sahip bir model oluşturmak için tüm özelliklerin korunmasına ihtiyaç duymayacağımızı gösterir.\n",
    "\n",
    "Görsel olarak karşılaştırmak için özellik önemlerini görselleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5dd955c4b8c2a8aa986fe0018e8ad45954ba06b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figsize(12, 10)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#En önemli 20 özelliği yatay bar çubuğundan görselleştirelim\n",
    "features_results.loc[:9, :].plot(x = 'features', y = 'importance',\n",
    "                               edgecolor = 'k',\n",
    "                               kind = 'barh', color = 'yellow');\n",
    "plt.xlabel('Bağıl Önem', size = 20); \n",
    "plt.ylabel('')\n",
    "plt.title('Rastgele Ormanda Özelliklerin önemi', size = 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8addbb967634e0ac7b13198c6112fca8c520ff97"
   },
   "source": [
    "## Özellik Seçimi için Önemli Özellikleri Kullanma\n",
    "Her özelliğin skoru bulmak için önemli olmadığı göz önüne alındığında, rasgele ormandaki en önemli özelliklerin alt kümesiyle doğrusal bir regresyon gibi daha basit bir model kullansaydık ne olurdu? Doğrusal regresyon, taban çizgisini geride bıraktı, ancak model karmaşık modellere kıyasla iyi performans göstermedi. Performansın iyileştirilip iyileştirilmediğini görmek için doğrusal regresyonda sadece en önemli 10 özelliği kullanmayı deneyelim. Ayrıca bu özellikleri sınırlayabilir ve rastgele ormanı yeniden değerlendirebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3082ea6d83fe3505a82dd2948aabd49f698d3a54",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#En Önemli Özellikleri ayıklıyoruz\n",
    "most_important_features = features_results['features'][:10]\n",
    "\n",
    "#Herbir özellik isminin indexini bulalım\n",
    "indices = [list(train_features.columns).index(x) for x in most_important_features]\n",
    "\n",
    "#Sadece en önemli özellikler kalıyor\n",
    "X_reduced =X[:, indices]\n",
    "X_test_reduced = X_test[:, indices]\n",
    "\n",
    "print('Eğitim setindeki en önemli özelliklerin şekli: ', X_reduced.shape)\n",
    "print('Test setindeki en önemli özelliklerin şekli: ', X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8480e1121ae110d5596b1b312410fba7731096b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "#Özelliklerin tamamına uyguluyoruz\n",
    "lr.fit(X, y)\n",
    "lr_full_pred = lr.predict(X_test)\n",
    "\n",
    "#Azaltılmış özelliklere uyguluyoruz\n",
    "lr.fit(X_reduced, y)\n",
    "lr_reduced_pred = lr.predict(X_test_reduced)\n",
    "\n",
    "#Sonuçları görüntülüyoruz\n",
    "print('Doğrusal Regresyonun tüm sonuçları: MAE =  %0.4f.' % mae(y_test, lr_full_pred))\n",
    "print('Doğrusal Regresyonun azaltılmış sonuçları : MAE = %0.4f.' % mae(y_test, lr_reduced_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e49f1129ac88ab12dbedaba7068bcfa20b0ed60f"
   },
   "source": [
    "Eh, özelliklerin azaltılması lineer regresyon sonuçlarını geliştirmedi! Düşük önem taşıyan özelliklerde ekstra bilgilerin gerçekte performansı artırdığı ortaya çıkmaktadır.\n",
    "\n",
    "Gradient(Eğim) artırılmış regresördeki azaltılmış özellik setini kullanalım. Bakalım modelimizin performans nasıl etkilenir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a3655e43c1332c299b82f4289e8db5719b7e7676",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Aynı hiperparametreler'den oluşan bir model oluşturuyoruz\n",
    "model_reduced = GradientBoostingRegressor(loss = 'lad', max_depth = 5, max_features = None,\n",
    "                                       min_samples_leaf = 6, min_samples_split =6, \n",
    "                                       n_estimators = 800, random_state = 42)\n",
    "#Özellikleri uygulayıp test ediyoruz\n",
    "model_reduced.fit(X_reduced, y)\n",
    "model_reduced_pred = model_reduced.predict(X_test_reduced)\n",
    "\n",
    "print('Eğimi artırılmışların azaltılmış sonuçları: MAE = %0.4f' % mae(y_test, model_reduced_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09e49f563967b7a5a4583b5ff2cda74e29be5099"
   },
   "source": [
    "Model sonuçları, azaltılmış özellik seti ile biraz daha kötüdür ve son model için tüm özellikleri koruyacağız. Özelliklerin sayısını azaltma arzusu, her zaman en karmaşık modeli oluşturmak istediğimiz içindir: yani, yeterli performansa sahip en basit model. Daha az özellik kullanan bir model daha hızlı eğitilecek ve genellikle daha kolay yorumlanacaktır. Bu durumda, tüm özelliklerin korunması önemli bir sorun değildir çünkü eğitim süresi önemli değildir ve hala birçok özellik ile yorum yapabiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32f1c5594957fa80e94155de4609d2390f29248d"
   },
   "source": [
    "## Lokal olarak Yorumlanabilir Model-agnostik Açıklamalar\n",
    "Model tarafından yapılan bireysel tahminleri açıklamak için LIME kullanımına bakacağız. LIME, bir makine öğrenim modelinin bölgeyi yaklaşık bir doğrusal modelle bir tahmin etrafında tahmin ederek nasıl düşündüğünü göstermeye yönelik nispeten yeni bir yaklaşımdır.\n",
    "\n",
    "Örnekle ilgili tahminleri açıklamaya çalışacağız, model çok yanlış ve örnek doğru bir örnek olabilir. Yorumlanabilirliğe yardımcı olmak için azaltılmış 10 özellik setini kullanmaya kendimizi kısıtlayacağız. En önemli 10 özellik üzerinde eğitilen model biraz daha az doğrudur, ancak genellikle yorumlanabilirlik için doğrulukla işimizi yapmak zorundayız!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "280012156e34c8032dd23170f160ee2297fb9448",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Azaltılmış değerleri buluyoruz\n",
    "residuals = abs(model_reduced_pred - y_test)\n",
    "\n",
    "#En iyi ve en kötü sonuçları görüntülüyoruz\n",
    "wrong = X_test_reduced[np.argmax(residuals), :]\n",
    "right = X_test_reduced[np.argmin(residuals), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65329e543e28d0032977bd4333bb35c4f4dd9d29",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Açıklayıcı(explainer) nesnesi oluşturuyoruz\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(training_data = X_reduced, \n",
    "                                                   mode = 'regression',\n",
    "                                                   training_labels = y,\n",
    "                                                   feature_names = list(most_important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ae425b345767a096a3fa30a12161bbca137c8a4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display the predicted and true value for the wrong instance\n",
    "print('Prediction: %0.4f' % model_reduced.predict(wrong.reshape(1, -1)))\n",
    "print('Actual Value: %0.4f' % y_test[np.argmax(residuals)])\n",
    "\n",
    "# Explanation for wrong prediction\n",
    "wrong_exp = explainer.explain_instance(data_row = wrong, \n",
    "                                       predict_fn = model_reduced.predict)\n",
    "\n",
    "# Plot the prediction explaination\n",
    "wrong_exp.as_pyplot_figure();\n",
    "plt.title('Explanation of Prediction', size = 28);\n",
    "plt.xlabel('Effect on Prediction', size = 22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76ec84c6ca5f74ef6f55b39a9d21f7a7807cab88",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_exp.show_in_notebook(show_predicted_value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6fc349965d0ddf2ec2ec56d49b7a4464fa91bac2"
   },
   "source": [
    "Bu örnekte, gradyan destekli modelimiz 12.86'lık bir skor öngördü ve gerçek değer 100'dü.\n",
    "\n",
    "LIME'den gelen görsel  bize örnek için her bir özellikten nihai tahminin katkısını ne olduğunu gösteriyor. Site EUI'sının tahminleri 95.50'nin üzerinde olması nedeniyle önemli ölçüde  tahminleri azalttığını görebiliriz. Hava Normalleştirilmiş Saha Elektrik Şiddeti, diğer taraftan, 3.80'den daha düşük olduğu için tahmini arttırdı.\n",
    "\n",
    "Bunu, modelimizin Enerji Yıldızı Puanının, Site EUI'sının yüksek olması nedeniyle olduğundan daha düşük olacağını düşündüğünü söyleyebiliriz. Ancak, bu durumda, EUI'nın yüksek değerine rağmen skor 100'dü. Bu kayda değer bir hata. Başlangıçta kafa karıştırıcı olabilirken, şimdi gerçekte, modelin problemle akıl yürüttüğünü ve yanlış değere ulaştığını görebiliriz! Aynı süreçten geçen bir insan muhtemelen aynı sonuca varırdı.(eğer tüm verilerden geçmek için sabır gösterebildiyse).\n",
    "\n",
    "Şimdi aynı süreci, modelin doğru olduğunu tahmin ederek inceleyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31bea28cbab75f4d501ae8ec90ef826add228681",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tahmin edilen ve gerçek değerlerin nasıl göründüğüne bakalım\n",
    "print('Tahmin: %0.4f' % model_reduced.predict(right.reshape(1, -1)))\n",
    "print('Gerçek Değer: %0.4f' % y_test[np.argmin(residuals)])\n",
    "\n",
    "# Yanlış tahminin açıklaması\n",
    "right_exp = explainer.explain_instance(right, model_reduced.predict, num_features=10)\n",
    "right_exp.as_pyplot_figure();\n",
    "plt.title('Tahminin Açıklaması', size = 28);\n",
    "plt.xlabel('Tahmin üzerindeki etkisi', size = 22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "562a5e9f3b7790d06a07f42827c432299b9fc17c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right_exp.show_in_notebook(show_predicted_value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32fee456117e62ad640d4b3af890ffb3f91c6756"
   },
   "source": [
    "Bu durum için doğru değer, gradyan destekli modelimizin doğru bir şekilde elde edildiği 100'dü!\n",
    "\n",
    "LIME'den gelen görsel yine örnek için her bir özellik değişkeninin önceliğine olan katkısını gösterir. Örneğin, Site EUI'si 62.70'den az olduğu için, bu puanın daha yüksek bir tahminine önemli ölçüde katkıda bulunmuştur. Aynı şekilde, 1927'den önce  inşa edilen yıl da nihai tahminlere olumlu katkıda bulundu.\n",
    "\n",
    "Bu gibi görselleri gözlemlemek, modelin bir öngörüyü nasıl yaptığı hakkında fikir edinmemize olanak tanır. Bu, büyük olasılıkla modelin kapalı olduğu durumlarda büyük bir değerdir, çünkü hataları daha iyi inceleyebilir ve belki de daha iyi özellikler geliştirebilir veya bir sonraki zaman için tahminleri geliştirmek  adına modelin hiperparametrelerini ayarlayabiliriz. Modelin en fazla kapalı olduğu örnekler, manuel olarak bakmak için ilginç kenar durumları da olabilir. Model, yükseltilmiş Site EUI'sı nedeniyle ilk bina için Enerji Yıldız Puanını büyük ölçüde küçümsedi. Bu nedenle, binanın bu kadar yüksek bir EUI'ye sahip olmasına rağmen neden bu kadar yüksek bir Enerji Yıldız Puanına sahip olduğunu sormak isteyebiliriz. Bir problemin anlaşılmasını sağlamak için makine öğrenimi algoritmasıyla çalışmaya çalıştığımız bu gibi bir süreç, modelin tahminler yapmasına ve tamamen onlara güvenmesine izin vermekten çok daha iyi görünüyor! LIME mükemmel olmasa da, makine öğrenim modellerini açıklamaya yönelik doğru yönde bir adımı temsil eder.\n",
    "\n",
    "## Tek Karar Ağacının İncelenmesi\n",
    "Ağaç tabanlı bir topluluk hakkındaki en havalı parçalardan biri, herhangi bir bireysel tahminciye bakabilmemiz. Her ne kadar son modelimiz 800 karar ağacından oluşuyor ve tek bir modele bakmak tüm modelin bir göstergesi değilse de, yine de bir karar ağacının nasıl işlediğine dair genel fikri görmemizi sağlıyor. Oradan, bu ağaçların yüzlerce ağacının, son bir tahminde bulunmak için önceki ağaçların hatalarını ortaya çıkardığını düşünmek doğal bir uzantıdır (bu, gradyanın gerilemesinin nasıl işlediğinin önemli bir basitleştirilmesidir!)\n",
    "\n",
    "Karar ağaçları ile ilgili detaylı bilgiyi aşağıdaki linklerden ulaşabilirsiniz.\n",
    "\n",
    "[link-1](https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d),\n",
    "[link-2](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b144aa56695702e0af3102d4aa21b761b116dd2a",
    "collapsed": true
   },
   "source": [
    "## Sonuç ve Değerlendirme\n",
    "Makine öğrenme hattının son kısmı en önemlisi olabilir: öğrendiğimiz her şeyi sadece en önemli bulguları vurgulayan kısa bir özet halinde sıkıştırmamız gerekiyor. Şahsen tüm teknik detayların açıklanmasından kaçınmakta zorlanıyorum çünkü tüm işlerin tadını çıkarıyorum. Bununla birlikte, sonuçlarınızı sunduğunuz kişinin tüm ayrıntıları dinlemek için çok fazla zamanı olmayabiliri ve sadece paketlerin tanıtımını yapmanızı istiyor olabilir. Veri bilimi veya makine öğrenimi projesinin en önemli unsurlarını çıkarmayı öğrenmek çok önemli bir beceridir çünkü eğer sonuçlarımız başkaları tarafından anlaşılmadıysa, asla kullanılmayacaktır!\n",
    "\n",
    "Kendi sonuç kümenizi bulmanızı öneririm, ancak burada 30 saniye içerisinde anlarılmak üzere  en önemli 2 durum belirtild:\n",
    "\n",
    " 1- Verilen bina enerji verilerini kullanarak, bir makine öğrenme modeli binanın Enerji Yıldızı Puanını 10 puan üzerinden tahmin edebilir.\n",
    " 2- Enerji Yıldızı Puanını belirlemek için en önemli değişkenler \"Enerji Kullanımı Yoğunluğu, Elektrik Kullanımı Yoğunluğu ve Su Kullanımı Yoğunluğu\"\n",
    " \n",
    "Eğer herhangi biri detay isterse, tüm uygulama adımlarını kolayca açıklayabilir ve (umarız) iyi belgelenmiş çalışmamızı sunabiliriz. Bir makine öğrenim projesinin bir diğer önemli yanı, tüm kodunuzu yorumlamak ve kodunuz takip etmenizi kolaylaştırmalıdır! İşinize bakabilmeniz ve yaptığınız kararları tamamen anlayabilmeniz için başkasının (ya da birkaç ay içinde kendinizin) olmasını istiyorsunuz. İdeal olarak, tekrar kullanacağı niyetiyle kod yazmalısınız. Projeleri kendimiz yapıyor olsak bile, doğru dokümantasyonu uygulamak iyidir ve bir projeyi tekrar gözden geçirmek istediğinizde hayatınızı kolaylaştıracaktır.\n",
    "\n",
    "Bu projeyi tamamlamanın zamanı geldi! Bu not defterlerini yazmak ve analiz yapmak için harika bir zaman geçirdim ve umarım bunu okumayı çok seversiniz ve şimdi kendi makine öğrenim projenizi yapmaya başlayabilirisniz. İsterseniz, bu projeyi değiştirerek ve modelleri yenmeye çalışarak başlayabilirsiniz! Unutmayın, tek başına gitmeniz gerektiğini düşünmeyin: aşağıdaki linkerde çok sayıda inanılmaz makine öğrenme kaynağı var ve büyük veri bilimi topluluğunun sayesinde tamamen kendi kendini öğreten birinden geliyor, öğrenmenin en iyi yolu işin içine gir ve işini oraya koymaya başla!\n",
    "\n",
    "### Makine Öğrenmesi ve Veri Bilimi İçin kaynaklar:\n",
    "\n",
    "   [link 1](http://shop.oreilly.com/product/0636920052289.do),\n",
    "   [link 2](https://github.com/ageron/handson-ml),\n",
    "   [link 3](http://www-bcf.usc.edu/~gareth/ISL/),\n",
    "   [link 4](https://www.kaggle.com/),\n",
    "   [link 5](https://www.datacamp.com/),\n",
    "   [link 6](https://www.dataquest.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
